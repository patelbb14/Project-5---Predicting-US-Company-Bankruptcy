








# Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import seaborn as sns

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix


from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline

import xgboost as xgb

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.callbacks import ReduceLROnPlateau


# Read data
df = pd.read_csv('data/american_bankruptcy.csv')


df['status_label'] = np.where(df['status_label'] == 'alive', 1, 0)


df['status_label'].value_counts()





# Define X and y
X=df.drop(columns=['company_name','status_label','year'])
y=df['status_label']


# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=666, stratify=y)


# Baseline prediction
y.mean()





# Correct class imbalances

# combine in a single dataframe
train_data = pd.concat([X_train, y_train], axis=1) 

# Separate the classes
class_0 = train_data[train_data[y_train.name] == 0] 
class_1 = train_data[train_data[y_train.name] == 1]

# Oversample y==0
class_0_oversampled = class_0.sample(len(class_1), replace=True, random_state=666)

# Combine balanced classes in a single dataframe
train_data_resampled = pd.concat([class_0_oversampled, class_1], axis=0)

#Shuffle the dataframe
train_data_resampled = train_data_resampled.sample(frac=1, random_state=666)


# Define new X and y variables after balancing classes

X_train_res = train_data_resampled.drop(y_train.name, axis=1)

y_train_res = train_data_resampled[y_train.name].astype('int64')

y_train_res.value_counts()











p = X_train_res.shape[1]

params = {
    'max_depth': np.append(np.arange(1, 12), None),
    'max_features': np.arange(1, p + 1),
    'min_samples_leaf': np.arange(1, 31)
}

rf = RandomForestClassifier(n_estimators=100, random_state=666)
rs = RandomizedSearchCV(rf, params, n_iter=100, cv=5, scoring='accuracy', n_jobs=8, random_state=666)


%%time
rs.fit(X_train_res, y_train_res) # only run if necessary


print("Best parameters:", rs.best_params_)
print("Best score:", rs.best_score_)


# Test the model
best_rf = RandomForestClassifier(**rs.best_params_, random_state=666)
best_rf.fit(X_train_res, y_train_res)

y_pred_rf = best_rf.predict(X_test)

test_accuracy = accuracy_score(y_test, y_pred_rf)

print(f"Test set accuracy: {test_accuracy:.4f}")





# Get the feature importances and sort them in descending order
sorted_importances = sorted(zip(X_train_res.columns, best_rf.feature_importances_), key=lambda x: x[1], reverse=True)

# Print the sorted feature importances
for feature, importance in sorted_importances:
    print(f"{feature}: {importance}")


# Confusion matrix

conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)

print("Confusion Matrix Random Forest:")
print(conf_matrix)











%%time
params = {
    'max_depth': np.arange(3, 10),
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300],
    'subsample': [0.8, 0.9, 1],
    'colsample_bytree': [0.8, 0.9, 1]
}

# Initialize the XGBoost classifier
xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=666)

# Initialize RandomizedSearchCV for hyperparameter tuning
rs_xgb = RandomizedSearchCV(xgb_clf, params, n_iter=50, cv=5, scoring='accuracy', n_jobs=8, random_state=666)

# Fit the RandomizedSearchCV object to the resampled training data
rs_xgb.fit(X_train_res, y_train_res)


print("Best parameters:", rs_xgb.best_params_)
print("Best score:", rs_xgb.best_score_)


# Use the best params to fit model and predict
best_xgb = xgb.XGBClassifier(**rs_xgb.best_params_, use_label_encoder=False, eval_metric='logloss', random_state=666)

best_xgb.fit(X_train_res, y_train_res)

y_pred_xgb = best_xgb.predict(X_test)

test_accuracy_xgb = accuracy_score(y_test, y_pred_xgb)

print(f"Test set accuracy XGBoost: {test_accuracy_xgb:.4f}")





# Get feature importances
feature_importances_xgb = best_xgb.get_booster().get_score(importance_type='weight')

# Sort feature importances in descending order
sorted_importances_xgb = sorted(feature_importances_xgb.items(), key=lambda x: x[1], reverse=True)

# Print sorted feature importances
print("Feature Importances:")
for feature, importance in sorted_importances_xgb:
    print(f"{feature}: {importance}")


# Confusion matrix

conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)

print("Confusion Matrix XGBoost:")
print(conf_matrix_xgb)











%%time
pipe_svc = Pipeline([
    ('scaler', StandardScaler()),
    ('svc', SVC(random_state=666))
])

param_grid_svc = [
    {
        'svc__C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter
        'svc__kernel': ['rbf']  # Kernel type
    },
    {
        'svc__C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter
        'svc__kernel': ['poly'],  # Kernel type
        'svc__degree': np.arange(2, 8)  # Degree of the polynomial kernel
    }
]

gs_svc = GridSearchCV(pipe_svc, param_grid_svc, cv=5, scoring='accuracy', n_jobs=8)

# Fit the GridSearchCV object to the resampled training data
gs_svc.fit(X_train_res, y_train_res)

# Print the best parameters and the corresponding score
print("Best parameters:", gs_svc.best_params_)
print("Best score:", gs_svc.best_score_)

# Use the best estimator to make predictions on the test set
y_pred_gs_svc = gs_svc.best_estimator_.predict(X_test)

# Calculate the accuracy on the test set
test_accuracy_gs_svc = accuracy_score(y_test, y_pred_gs_svc)

print(f"Test set accuracy with GridSearchCV SVC: {test_accuracy_gs_svc:.4f}")


# Confusion matrix

conf_matrix_svc = confusion_matrix(y_test, y_pred_svc)
print("Confusion Matrix SVM:")
print(conf_matrix_svc)











# Scale the data
scaler = StandardScaler()
X_train_res_scaled = scaler.fit_transform(X_train_res)
X_test_scaled = scaler.transform(X_test)


# Define the neural network architecture
model6 = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_res_scaled.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile the model
model6.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history6 = model6.fit(X_train_res_scaled, y_train_res,
                    validation_data=(X_test_scaled, y_test),
                    epochs=50,
                    batch_size=32,
                    callbacks=[early_stopping])

# Evaluate the model on the test set
test_loss, test_accuracy = model6.evaluate(X_test_scaled, y_test)
print(f"Test accuracy: {test_accuracy:.4f}")


# Predict the labels for the test set
y_pred = model6.predict(X_test_scaled)
y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix)





# Accuracy plot
models = ['Random Forest', 'XGBoost', 'Neural Net', 'SVM']
accuracies = [0.9407, 0.9395, 0.8343, 0.4071]
# baseline = 0.9336

plt.figure(figsize=(8, 6))
plt.barh(models, accuracies, color='darkblue')
# plt.axvline(x=baseline, color='red', linestyle='--', label=f'Baseline = {baseline}')
plt.xlabel('Accuracy')
plt.ylabel('Model')
plt.title('Accuracy by Model')
# plt.legend()
plt.show()


# Improvement in Accuracy plot
models = ['Random Forest', 'XGBoost']
accuracies = [(0.9407-0.9336)*100, (0.9395-0.9336)*100]
# baseline = 0.9336

plt.figure(figsize=(8, 6))
plt.barh(models, accuracies, color='darkblue')
# plt.axvline(x=baseline, color='red', linestyle='--', label=f'Baseline = {baseline}')
plt.xlabel('Difference with baseline (%)')
plt.ylabel('Model')
plt.title('Improvement in Accuracy by Model (Baseline = 93%)')
# plt.legend()
plt.show()
